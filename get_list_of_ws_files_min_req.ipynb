{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing only the weather stations that have at least the minimum columns we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed for file operations\n",
    "import os\n",
    "\n",
    "# needed for data manipulation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1000 of 78956\n",
      "Processing file 2000 of 78956\n",
      "Processing file 3000 of 78956\n",
      "Processing file 4000 of 78956\n",
      "Processing file 5000 of 78956\n",
      "Processing file 6000 of 78956\n",
      "Processing file 7000 of 78956\n",
      "Processing file 8000 of 78956\n",
      "Processing file 9000 of 78956\n",
      "Processing file 10000 of 78956\n",
      "Processing file 11000 of 78956\n",
      "Processing file 12000 of 78956\n",
      "Processing file 13000 of 78956\n",
      "Processing file 14000 of 78956\n",
      "Processing file 15000 of 78956\n",
      "Processing file 16000 of 78956\n",
      "Processing file 17000 of 78956\n",
      "Processing file 18000 of 78956\n",
      "Processing file 19000 of 78956\n",
      "Processing file 20000 of 78956\n",
      "Processing file 21000 of 78956\n",
      "Processing file 22000 of 78956\n",
      "Processing file 23000 of 78956\n",
      "Processing file 24000 of 78956\n",
      "Processing file 25000 of 78956\n",
      "Processing file 26000 of 78956\n",
      "Processing file 27000 of 78956\n",
      "Processing file 28000 of 78956\n",
      "Processing file 29000 of 78956\n",
      "Processing file 30000 of 78956\n",
      "Processing file 31000 of 78956\n",
      "Processing file 32000 of 78956\n",
      "Processing file 33000 of 78956\n",
      "Processing file 34000 of 78956\n",
      "Processing file 35000 of 78956\n",
      "Processing file 36000 of 78956\n",
      "Processing file 37000 of 78956\n",
      "Processing file 38000 of 78956\n",
      "Processing file 39000 of 78956\n",
      "Processing file 40000 of 78956\n",
      "Processing file 41000 of 78956\n",
      "Processing file 42000 of 78956\n",
      "Processing file 43000 of 78956\n",
      "Processing file 44000 of 78956\n",
      "Processing file 45000 of 78956\n",
      "Processing file 46000 of 78956\n",
      "Processing file 47000 of 78956\n",
      "Processing file 48000 of 78956\n",
      "Processing file 49000 of 78956\n",
      "Processing file 50000 of 78956\n",
      "Processing file 51000 of 78956\n",
      "Processing file 52000 of 78956\n",
      "Processing file 53000 of 78956\n",
      "Processing file 54000 of 78956\n",
      "Processing file 55000 of 78956\n",
      "Processing file 56000 of 78956\n",
      "Processing file 57000 of 78956\n",
      "Processing file 58000 of 78956\n",
      "Processing file 59000 of 78956\n",
      "Processing file 60000 of 78956\n",
      "Processing file 61000 of 78956\n",
      "Processing file 62000 of 78956\n",
      "Processing file 63000 of 78956\n",
      "Processing file 64000 of 78956\n",
      "Processing file 65000 of 78956\n",
      "Processing file 66000 of 78956\n",
      "Processing file 67000 of 78956\n",
      "Processing file 68000 of 78956\n",
      "Processing file 69000 of 78956\n",
      "Processing file 70000 of 78956\n",
      "Processing file 71000 of 78956\n",
      "Processing file 72000 of 78956\n",
      "Processing file 73000 of 78956\n",
      "Processing file 74000 of 78956\n",
      "Processing file 75000 of 78956\n",
      "Processing file 76000 of 78956\n",
      "Processing file 77000 of 78956\n",
      "Processing file 78000 of 78956\n"
     ]
    }
   ],
   "source": [
    "list_of_files_to_keep = []\n",
    "dir_with_raw_data_files = \"F:/Libraries/My Documents/UM/Capstone/RawData\"\n",
    "\n",
    "# get the list of weather station files that are within my lat/long box (output of previous step)\n",
    "file_path = \"F:/Libraries/My Documents/UM/Capstone/datafiles_in_range.txt\"\n",
    "ws_file_list = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        ws_file_list.append(line.strip())\n",
    "\n",
    "# for each of these weather station files, see which ones have the minimum subset of columns that we want\n",
    "min_columns_we_need = ['DATE', 'LATITUDE', 'LONGITUDE', 'NAME', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN']\n",
    "i = 0\n",
    "for file in ws_file_list:\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Processing file {i} of {len(ws_file_list)}\")\n",
    "    file_path = os.path.join(dir_with_raw_data_files, file)\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    if set(df.columns).issuperset(min_columns_we_need):\n",
    "        list_of_files_to_keep.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16460\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_files_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"F:/Libraries/My Documents/UM/Capstone/datafiles_in_range_meet_data_req.txt\"\n",
    "with open(file_path, 'w') as f:\n",
    "    for file in list_of_files_to_keep:\n",
    "        f.write(file + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
